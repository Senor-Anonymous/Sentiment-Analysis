{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNf4DU3EPv9rE8oTINZCmGJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Senor-Anonymous/Sentiment-Analysis/blob/main/Week%201/lexicon_sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cbd75a5"
      },
      "source": [
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from textblob import TextBlob\n",
        "from collections import Counter\n",
        "\n",
        "class LexiconSentimentAnalyzer:\n",
        "    def __init__(self):\n",
        "        try:\n",
        "            nltk.data.find('sentiment/vader_lexicon.zip')\n",
        "        except LookupError:\n",
        "            nltk.download('vader_lexicon', quiet=True)\n",
        "\n",
        "        try:\n",
        "            nltk.data.find('tokenizers/punkt')\n",
        "        except LookupError:\n",
        "            nltk.download('punkt', quiet=True)\n",
        "\n",
        "\n",
        "        try:\n",
        "            nltk.data.find('tokenizers/punkt_tab')\n",
        "        except LookupError:\n",
        "            nltk.download('punkt_tab', quiet=True)\n",
        "\n",
        "        self.vader_analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "        self.custom_lexicon = {\n",
        "            'profit': 1.0,\n",
        "            'growth': 0.8,\n",
        "            'increase': 0.7,\n",
        "            'positive': 0.6,\n",
        "            'strong': 0.5,\n",
        "            'neutral': 0.0,\n",
        "            'stable': 0.1,\n",
        "            'decline': -0.7,\n",
        "            'loss': -1.0,\n",
        "            'crisis': -0.9,\n",
        "            'negative': -0.6,\n",
        "            'weak': -0.5\n",
        "        }\n",
        "\n",
        "        print(\"LexiconSentimentAnalyzer initialized with VADER, TextBlob, and custom lexicon.\")\n",
        "\n",
        "    def vader_sentiment(self, text):\n",
        "        scores = self.vader_analyzer.polarity_scores(text)\n",
        "        compound_score = scores['compound']\n",
        "\n",
        "        if compound_score >= 0.05:\n",
        "            sentiment_label = 'positive'\n",
        "        elif compound_score <= -0.05:\n",
        "            sentiment_label = 'negative'\n",
        "        else:\n",
        "            sentiment_label = 'neutral'\n",
        "\n",
        "        return {\n",
        "            'compound': compound_score,\n",
        "            'label': sentiment_label\n",
        "        }\n",
        "\n",
        "    def textblob_sentiment(self, text):\n",
        "        blob = TextBlob(text)\n",
        "        polarity_score = blob.sentiment.polarity\n",
        "        if polarity_score >= 0.05:\n",
        "            sentiment_label = 'positive'\n",
        "        elif polarity_score <= -0.05:\n",
        "            sentiment_label = 'negative'\n",
        "        else:\n",
        "            sentiment_label = 'neutral'\n",
        "\n",
        "        return {\n",
        "            'polarity': polarity_score,\n",
        "            'label': sentiment_label\n",
        "        }\n",
        "\n",
        "    def custom_lexicon_sentiment(self, text):\n",
        "        text_lower = text.lower()\n",
        "        words = nltk.word_tokenize(text_lower)\n",
        "\n",
        "        sentiment_score = 0.0\n",
        "        matched_words_count = 0\n",
        "        for word in words:\n",
        "            if word in self.custom_lexicon:\n",
        "                sentiment_score += self.custom_lexicon[word]\n",
        "                matched_words_count += 1\n",
        "        custom_score = 0.0\n",
        "        if matched_words_count > 0:\n",
        "            custom_score = sentiment_score / matched_words_count\n",
        "\n",
        "        return custom_score\n",
        "\n",
        "    def analyze(self, text):\n",
        "        vader_result = self.vader_sentiment(text)\n",
        "        textblob_result = self.textblob_sentiment(text)\n",
        "\n",
        "        vader_compound = vader_result['compound']\n",
        "        textblob_polarity = textblob_result['polarity']\n",
        "        custom_score= self.custom_lexicon_sentiment(text)\n",
        "        vader_label = vader_result['label']\n",
        "        textblob_label = textblob_result['label']\n",
        "        ensemble_score = (abs(vader_compound) + abs(textblob_polarity) + abs(custom_score)) / 3\n",
        "\n",
        "        labels = [vader_label, textblob_label]\n",
        "        label_counts = Counter(labels)\n",
        "\n",
        "        # Get the most common label(s)\n",
        "        most_common = label_counts.most_common()\n",
        "        def sentiment_priority(label):\n",
        "            if label == 'positive': return 2\n",
        "            if label == 'neutral': return 1\n",
        "            return 0\n",
        "        if len(most_common) > 1 and most_common[0][1] == most_common[1][1]:\n",
        "            tied_labels = [label for label, count in most_common if count == most_common[0][1]]\n",
        "\n",
        "            ensemble_label = sorted(tied_labels, key=sentiment_priority, reverse=True)[0]\n",
        "        else:\n",
        "            ensemble_label = most_common[0][0]\n",
        "\n",
        "\n",
        "        confidence_score = label_counts[ensemble_label] / len(labels)\n",
        "\n",
        "        return {\n",
        "            'text': text,\n",
        "            'vader': vader_result,\n",
        "            'textblob': textblob_result,\n",
        "            'custom_score': custom_score,\n",
        "            'ensemble_score': ensemble_score,\n",
        "            'confidence_score': confidence_score\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69949a62",
        "outputId": "5ee00bc0-d865-4bd8-9337-120e48e9654c"
      },
      "source": [
        "sample_text = 'Excellent earnings beat expectations'\n",
        "sample_analysis_result = analyzer.analyze(sample_text)\n",
        "\n",
        "print(f\"\\nAnalysis for: '{sample_text}'\")\n",
        "print(sample_analysis_result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Analysis for: 'Excellent earnings beat expectations'\n",
            "{'text': 'Excellent earnings beat expectations', 'vader': {'compound': 0.5719, 'label': 'positive'}, 'textblob': {'polarity': 1.0, 'label': 'positive'}, 'custom_score': 0.0, 'ensemble_score': 0.5239666666666666, 'confidence_score': 1.0}\n"
          ]
        }
      ]
    }
  ]
}